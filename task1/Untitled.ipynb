{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data(file_name):\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(file_name)\n",
    "    for line in fr.readlines()[1:]:\n",
    "        line = line.strip().split()\n",
    "        dataMat.append([line[0], line[1], ' '.join(line[2:-1])])\n",
    "        labelMat.append(line[-1])\n",
    "    return dataMat, labelMat\n",
    "\n",
    "\n",
    "def create_dic(dataMat):\n",
    "    Dict = []\n",
    "    for line in dataMat:\n",
    "        line = line[2].split()\n",
    "        for element in line:\n",
    "            if element not in Dict and element not in [',', '.']:\n",
    "                Dict.append(element)\n",
    "    return Dict\n",
    "\n",
    "\n",
    "def create_vector(dict_, dataMat):\n",
    "    m = len(dataMat)\n",
    "    n = len(dict_)\n",
    "    dataMatrix = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        line = dataMat[i][2].strip().split()\n",
    "        for word in line:\n",
    "            if word not in dict_:\n",
    "                continue\n",
    "            if word not in [',', '.']:\n",
    "                dataMatrix[i][dict_.index(word)] = 1\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x_vector):\n",
    "    exps = np.exp(x_vector)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(X,y):\n",
    "    \"\"\"\n",
    "    X is the output from fully connected layer (num_examples x num_classes)\n",
    "    y is labels (num_examples x 1)\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    for i in range(m):\n",
    "        X[i] = softmax(X[i])\n",
    "    #log_likelihood = -np.log(p[range(m),y])\n",
    "    loss = X - y\n",
    "    print(X)\n",
    "    #loss = np.sum(log_likelihood) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradAscent(dataMat, classLabels):\n",
    "    dataMat = np.mat(dataMat)\n",
    "    classLabels = np.mat(classLabels)\n",
    "    m, n = np.shape(dataMat)\n",
    "    # print(n, m)\n",
    "    alpha = 0.01\n",
    "    maxCycles = 2000\n",
    "    weights = np.random.rand(n, 5)\n",
    "    \n",
    "    print(np.dot(dataMat, weights))\n",
    "\n",
    "    for i in range(maxCycles):\n",
    "        error = cross_entropy(np.dot(dataMat, weights), classLabels)\n",
    "        weights -= alpha * np.dot(dataMat.transpose(), error)\n",
    "        print(i, ': ', np.sum(error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat, labelMat = load_data('train.tsv')\n",
    "labelMat = [int(x) for x in labelMat]\n",
    "y = np.zeros((len(dataMat), 5))\n",
    "for i in range(len(dataMat)):\n",
    "    y[i][labelMat[i]-1] = 1\n",
    "testMat, _ = load_data('test.tsv')\n",
    "if os.path.exists('dict.txt'):\n",
    "    fr = open('dict.txt', 'r')\n",
    "    Dict = fr.readline().strip().split()\n",
    "else:\n",
    "    Dict = create_dic(dataMat)\n",
    "    fw = open('dict.txt', 'w')\n",
    "    fw.write(' '.join(Dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix = create_vector(Dict, dataMat)\n",
    "testMatrix = create_vector(Dict, testMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060 18224 156060\n"
     ]
    }
   ],
   "source": [
    "print(len(dataMatrix),len(dataMatrix[0]), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.67000413 10.28916574 13.20754572 13.44419972 14.09846433]\n",
      " [ 7.76587631  5.25602603  6.35522489  7.03754744  7.01112961]\n",
      " [ 1.69168112  0.76203062  1.2399424   0.42366774  1.65259793]\n",
      " ...\n",
      " [ 1.76685218  1.54799362  0.74603087  1.31535243  1.25791263]\n",
      " [ 0.89338516  0.8216201   0.44242792  0.57864957  0.80911848]\n",
      " [ 0.87346702  0.72637352  0.30360295  0.73670286  0.44879415]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-936ba5b37bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradAscent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-fb5be0654ae2>\u001b[0m in \u001b[0;36mgradAscent\u001b[0;34m(dataMat, classLabels)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxCycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gradAscent(dataMatrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
